{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load course date info over!\n",
      "number of courses: 39\n",
      "load course object info over!\n",
      "number of courses: 39\n",
      "number of moduels: 26750\n",
      "load course object info over!\n",
      "size of log data: 4677908\n",
      "number of enrollment_ids: 72395\n",
      "load enrollment info over!\n",
      "number of courses: 39\n",
      "number of enrollments: 72395\n",
      "number of uers:  53870\n",
      "load truth info over!\n",
      "number of labels: 72395\n",
      "load course date info over!\n",
      "number of courses: 39\n",
      "load course object info over!\n",
      "number of courses: 39\n",
      "number of moduels: 26750\n",
      "load course object info over!\n",
      "size of log data: 1548480\n",
      "number of enrollment_ids: 24013\n",
      "load enrollment info over!\n",
      "number of courses: 39\n",
      "number of enrollments: 24013\n",
      "number of uers:  21266\n",
      "load truth info over!\n",
      "number of labels: 24013\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from preprocess import Preprocessor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "p_train = Preprocessor('train')\n",
    "p_test = Preprocessor('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_count features extracted! 1.344419 seconds taken\n",
      "Shape of the event_count dataframe:  (72395, 8)\n",
      "weekly_session_count features extracted! 60.504248 seconds taken\n",
      "Shape of the weekly_session_count dataframe:  (72395, 6)\n",
      "problem_video_ratio features extracted! 3.183553 seconds taken\n",
      "Shape of the problem_video dataframe:  (72395, 3)\n",
      "All features extracted! 65.190826 seconds taken\n",
      "Shape of the whole features dataframe:  (72395, 16)\n",
      "Getting train data preprocessing done! 65.286530 seconds taken\n",
      "Getting raw values for X, y done!\n",
      "The shape of X: (72395, 15); shape of y: (72395,)\n"
     ]
    }
   ],
   "source": [
    "X_train_all, y_train_all = p_train.get_values_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_count features extracted! 0.417885 seconds taken\n",
      "Shape of the event_count dataframe:  (24013, 8)\n",
      "weekly_session_count features extracted! 18.258213 seconds taken\n",
      "Shape of the weekly_session_count dataframe:  (24013, 6)\n",
      "problem_video_ratio features extracted! 1.017272 seconds taken\n",
      "Shape of the problem_video dataframe:  (24013, 3)\n",
      "All features extracted! 19.747248 seconds taken\n",
      "Shape of the whole features dataframe:  (24013, 16)\n",
      "Getting test data preprocessing done! 19.766196 seconds taken\n",
      "Getting raw values for X, y done!\n",
      "The shape of X: (24013, 15); shape of y: (24013,)\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = p_test.get_values_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=3, learning_rate=0.05, max_delta_step=1,\n",
       "       max_depth=6, min_child_weight=2, missing=None, n_estimators=200,\n",
       "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(n_estimators=200, max_depth=6, learning_rate=0.05, min_child_weight=2, n_jobs=-1, max_delta_step=1, \n",
    "                      objective='binary:logistic', gamma=3 ,subsample=1)\n",
    "model.fit(X_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.57      0.66      4902\n",
      "          1       0.90      0.96      0.93     19111\n",
      "\n",
      "avg / total       0.87      0.88      0.87     24013\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kang\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.8024%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.4f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier LogisticRegression(C=1.5, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.001,\n",
      "          verbose=0, warm_start=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.54      0.64      4902\n",
      "          1       0.89      0.96      0.92     19111\n",
      "\n",
      "avg / total       0.87      0.87      0.87     24013\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 2624  2278]\n",
      " [  736 18375]]\n",
      "Score: \n",
      "87.4485%\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = LogisticRegression(tol=1e-3, C=1.5, random_state=0)\n",
    "clf = clf.fit(X_train_all, y_train_all)\n",
    "expected = y_test\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (clf, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "print ('Score: ')\n",
    "print (\"%.4f%%\" % (clf.score(X_test,y_test) * 100.0))\n",
    "# print ('Cross validation score: ')\n",
    "# print (cross_val_score(clf, X_train_all, y_train_all, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.05, loss='deviance', max_depth=6,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "              presort='auto', random_state=0, subsample=1.0, verbose=0,\n",
      "              warm_start=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.57      0.65      4902\n",
      "          1       0.90      0.96      0.92     19111\n",
      "\n",
      "avg / total       0.87      0.88      0.87     24013\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 2774  2128]\n",
      " [  836 18275]]\n",
      "Score: \n",
      "87.6567%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=200, max_depth=6, learning_rate=0.05, random_state=0)\n",
    "clf = clf.fit(X_train_all, y_train_all)\n",
    "expected = y_test\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (clf, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "print ('Score: ')\n",
    "print (\"%.4f%%\" % (clf.score(X_test,y_test) * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=3,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.56      0.65      4902\n",
      "          1       0.89      0.96      0.92     19111\n",
      "\n",
      "avg / total       0.87      0.88      0.87     24013\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 2736  2166]\n",
      " [  808 18303]]\n",
      "Score: \n",
      "87.6150%\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=200, max_depth=12, random_state=0, min_samples_split=3, n_jobs=-1)\n",
    "clf = clf.fit(X_train_all, y_train_all)\n",
    "expected = y_test\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (clf, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "print ('Score: ')\n",
    "print (\"%.4f%%\" % (clf.score(X_test,y_test) * 100.0))\n",
    "# print (cross_val_score(clf, X_train_all, y_train_all, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(64, 32), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.56      0.64      4902\n",
      "          1       0.89      0.95      0.92     19111\n",
      "\n",
      "avg / total       0.87      0.87      0.87     24013\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 2763  2139]\n",
      " [  903 18208]]\n",
      "Score: \n",
      "87.3319%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(hidden_layer_sizes=(64,32))\n",
    "\n",
    "clf = clf.fit(X_train_all, y_train_all)\n",
    "expected = y_test\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (clf, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "print ('Score: ')\n",
    "print (\"%.4f%%\" % (clf.score(X_test,y_test) * 100.0))\n",
    "# print (cross_val_score(clf, X_train_all, y_train_all, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_count features extracted! 1.217704 seconds taken\n",
      "Shape of the event_count dataframe:  (72395, 8)\n",
      "weekly_session_count features extracted! 51.340733 seconds taken\n",
      "Shape of the weekly_session_count dataframe:  (72395, 6)\n",
      "problem_video_ratio features extracted! 3.045905 seconds taken\n",
      "Shape of the problem_video dataframe:  (72395, 3)\n",
      "All features extracted! 55.734944 seconds taken\n",
      "Shape of the whole features dataframe:  (72395, 16)\n"
     ]
    }
   ],
   "source": [
    "f = clf_all.feature_importances_\n",
    "c = p_train.get_features_all().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'access_count': 0.15930482937723603,\n",
       " 'discussion_count': 0.04269388956217597,\n",
       " 'navigate_count': 0.09841600852514756,\n",
       " 'page_close_count': 0.09697023842232648,\n",
       " 'problem_count': 0.0692296509961611,\n",
       " 'video_count': 0.061399968295089785,\n",
       " 'wiki_count': 0.023401594378286227,\n",
       " 'week_one_session': 0.023761561767072562,\n",
       " 'week_two_session': 0.03402435521352029,\n",
       " 'week_three_session': 0.033797121619515834,\n",
       " 'week_four_session': 0.05919820710931555,\n",
       " 'week_five_session': 0.10147390902438054,\n",
       " 'week_six_session': 0.006813039525642023,\n",
       " 'problem_ratio': 0.11000736983283753,\n",
       " 'video_ratio': 0.07950825635129263}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d={}\n",
    "for i in range(len(f)):\n",
    "    d[c[i+1]] = f[i]\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_count features extracted! 1.652582 seconds taken\n",
      "Shape of the event_count dataframe:  (72395, 8)\n",
      "weekly_session_count features extracted! 54.183138 seconds taken\n",
      "Shape of the weekly_session_count dataframe:  (72395, 6)\n",
      "problem_video_ratio features extracted! 3.300178 seconds taken\n",
      "Shape of the problem_video dataframe:  (72395, 3)\n",
      "All features extracted! 59.294496 seconds taken\n",
      "Shape of the whole features dataframe:  (72395, 16)\n",
      "Getting train data preprocessing done! 59.346373 seconds taken\n",
      "Getting partial X, y done!\n",
      "The shape of X: (37975, 15); shape of y: (37975,)\n",
      "The ratio of 1 in labels:  60.42%\n"
     ]
    }
   ],
   "source": [
    "X_train_balance, y_train_balance = p_train.get_values_partial(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=3, learning_rate=0.05, max_delta_step=1,\n",
       "       max_depth=6, min_child_weight=2, missing=None, n_estimators=200,\n",
       "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model_partial = XGBClassifier(n_estimators=200, max_depth=6, learning_rate=0.05, min_child_weight=2, n_jobs=-1, max_delta_step=1, \n",
    "                      objective='binary:logistic', gamma=3 ,subsample=1)\n",
    "model_partial.fit(X_train_balance, y_train_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.69      0.67      4902\n",
      "          1       0.92      0.90      0.91     19111\n",
      "\n",
      "avg / total       0.86      0.86      0.86     24013\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kang\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_partial.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.7619%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.4f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
       "            oob_score=False, random_state=520, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_partial = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=520)\n",
    "clf_partial.fit(X_train_balance, y_train_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.71      0.64      4902\n",
      "          1       0.92      0.87      0.90     19111\n",
      "\n",
      "avg / total       0.85      0.84      0.84     24013\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, clf_partial.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
