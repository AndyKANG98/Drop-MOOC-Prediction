{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load course date info over!\n",
      "('number of courses:', 39)\n",
      "load course object info over!\n",
      "('number of courses:', 39)\n",
      "('number of moduels:', 26750)\n",
      "load course object info over!\n",
      "('size of log data:', 4677908)\n",
      "('number of enrollment_ids:', 72395)\n",
      "load enrollment info over!\n",
      "('number of courses:', 39)\n",
      "('number of enrollments:', 72395)\n",
      "('number of uers: ', 53870)\n",
      "load truth info over!\n",
      "('number of labels:', 72395)\n",
      "load course date info over!\n",
      "('number of courses:', 39)\n",
      "load course object info over!\n",
      "('number of courses:', 39)\n",
      "('number of moduels:', 26750)\n",
      "load course object info over!\n",
      "('size of log data:', 1548480)\n",
      "('number of enrollment_ids:', 24013)\n",
      "load enrollment info over!\n",
      "('number of courses:', 39)\n",
      "('number of enrollments:', 24013)\n",
      "('number of uers: ', 21266)\n",
      "load truth info over!\n",
      "('number of labels:', 24013)\n",
      "event_count features extracted! 1.532409 seconds taken\n",
      "('Shape of the event_count dataframe: ', (72395, 8))\n",
      "weekly_event_count features extracted! 3.781156 seconds taken\n",
      "('Shape of the weekly_event_count dataframe: ', (72395, 7))\n",
      "weekly_session_count features extracted! 63.054942 seconds taken\n",
      "('Shape of the weekly_session_count dataframe: ', (72395, 6))\n",
      "All features extracted! 68.490900 seconds taken\n",
      "('Shape of the whole features dataframe: ', (72395, 20))\n",
      "Getting raw values for X, y done!\n",
      "The shape of X: (72395, 19); shape of y: (72395,)\n",
      "event_count features extracted! 0.357346 seconds taken\n",
      "('Shape of the event_count dataframe: ', (24013, 8))\n",
      "weekly_event_count features extracted! 1.256404 seconds taken\n",
      "('Shape of the weekly_event_count dataframe: ', (24013, 7))\n",
      "weekly_session_count features extracted! 18.106572 seconds taken\n",
      "('Shape of the weekly_session_count dataframe: ', (24013, 6))\n",
      "All features extracted! 19.757580 seconds taken\n",
      "('Shape of the whole features dataframe: ', (24013, 20))\n",
      "Getting raw values for X, y done!\n",
      "The shape of X: (24013, 19); shape of y: (24013,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from preprocess import Preprocessor\n",
    "# Scikit Learn Libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def random_forest(X_train, y_train, X_test, y_test, N_estimators=500):\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=500)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    expected = y_test\n",
    "    predicted = clf.predict(X_test)\n",
    "\n",
    "    print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "          % (clf, metrics.classification_report(expected, predicted)))\n",
    "    print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "    print 'Score: '\n",
    "    print clf.score(X_test,y_test)\n",
    "\n",
    "def SVM(X_train, y_train, X_test, y_test, Gamma='scale'):\n",
    "\n",
    "    clf = svm.SVC(gamma='scale') \n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    expected = y_test\n",
    "    predicted = clf.predict(X_test)\n",
    "\n",
    "    print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "          % (clf, metrics.classification_report(expected, predicted)))\n",
    "    print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "    print 'Score: '\n",
    "    print clf.score(X_test,y_test)\n",
    "    print 'Cross validation score: '\n",
    "    print cross_val_score(clf, X_train, y_train, cv=3)\n",
    "    \n",
    "def MLPClassifier(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    clf = MLPClassifier()\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    expected = y_test\n",
    "    predicted = clf.predict(X_test)\n",
    "\n",
    "    print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "          % (clf, metrics.classification_report(expected, predicted)))\n",
    "    print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "    print 'Score: '\n",
    "    print clf.score(X_test,y_test)\n",
    "    print 'Cross validation score: '\n",
    "    print cross_val_score(clf, X_train, y_train, cv=3)\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    \n",
    "    # Build preprocessor\n",
    "    p_train = Preprocessor('train')\n",
    "    p_test = Preprocessor('test')\n",
    "    \n",
    "    # Get value\n",
    "    X_train, y_train = p_train.get_values_all()\n",
    "    X_test, y_test = p_test.get_values_all()\n",
    "    \n",
    "    # Random forest: N_estimators\n",
    "    random_forest(X_train, y_train, X_test, y_test, N_estimators=500)\n",
    "    \n",
    "    # SVM: gamma\n",
    "    SVM(X_train, y_train, X_test, y_test, Gamma='scale')\n",
    "    \n",
    "    # Neural network\n",
    "    neural_network(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "\n",
    "if __name__== \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named xgboost",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7adc2093e82b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named xgboost"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from preprocess import Preprocessor\n",
    "# Libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load course date info over!\n",
      "('number of courses:', 39)\n",
      "load course object info over!\n",
      "('number of courses:', 39)\n",
      "('number of moduels:', 26750)\n",
      "load course object info over!\n",
      "('size of log data:', 4677908)\n",
      "('number of enrollment_ids:', 72395)\n",
      "load enrollment info over!\n",
      "('number of courses:', 39)\n",
      "('number of enrollments:', 72395)\n",
      "('number of uers: ', 53870)\n",
      "load truth info over!\n",
      "('number of labels:', 72395)\n",
      "load course date info over!\n",
      "('number of courses:', 39)\n",
      "load course object info over!\n",
      "('number of courses:', 39)\n",
      "('number of moduels:', 26750)\n",
      "load course object info over!\n",
      "('size of log data:', 1548480)\n",
      "('number of enrollment_ids:', 24013)\n",
      "load enrollment info over!\n",
      "('number of courses:', 39)\n",
      "('number of enrollments:', 24013)\n",
      "('number of uers: ', 21266)\n",
      "load truth info over!\n",
      "('number of labels:', 24013)\n",
      "event_count features extracted! 1.141020 seconds taken\n",
      "('Shape of the event_count dataframe: ', (72395, 8))\n",
      "weekly_session_count features extracted! 63.178121 seconds taken\n",
      "('Shape of the weekly_session_count dataframe: ', (72395, 6))\n",
      "problem_video_ratio features extracted! 3.265956 seconds taken\n",
      "('Shape of the problem_video dataframe: ', (72395, 3))\n",
      "All features extracted! 67.717514 seconds taken\n",
      "('Shape of the whole features dataframe: ', (72395, 16))\n",
      "Getting data preprocessing done! 67.724508 seconds taken\n",
      "Getting raw values for X, y done!\n",
      "The shape of X: (72395, 15); shape of y: (72395,)\n",
      "event_count features extracted! 0.385512 seconds taken\n",
      "('Shape of the event_count dataframe: ', (24013, 8))\n",
      "weekly_session_count features extracted! 19.858744 seconds taken\n",
      "('Shape of the weekly_session_count dataframe: ', (24013, 6))\n",
      "problem_video_ratio features extracted! 1.109778 seconds taken\n",
      "('Shape of the problem_video dataframe: ', (24013, 3))\n",
      "All features extracted! 21.403260 seconds taken\n",
      "('Shape of the whole features dataframe: ', (24013, 16))\n",
      "Getting data preprocessing done! 21.406489 seconds taken\n",
      "Getting raw values for X, y done!\n",
      "The shape of X: (24013, 15); shape of y: (24013,)\n"
     ]
    }
   ],
   "source": [
    "# Build preprocessor\n",
    "p_train = Preprocessor('train')\n",
    "p_test = Preprocessor('test')\n",
    "\n",
    "# Get value\n",
    "X_train, y_train = p_train.get_values_all()\n",
    "X_test, y_test = p_test.get_values_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.57      0.65      4902\n",
      "           1       0.90      0.95      0.92     19111\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     24013\n",
      "   macro avg       0.82      0.76      0.78     24013\n",
      "weighted avg       0.87      0.87      0.87     24013\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 2785  2117]\n",
      " [  924 18187]]\n",
      "Score: \n",
      "0.8733602631907716\n",
      "[0.87051105 0.87436978 0.87354099 0.87257407 0.87263434]\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "expected = y_test\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (clf, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "print 'Score: '\n",
    "print clf.score(X_test,y_test)\n",
    "print cross_val_score(clf, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.58      0.64      4902\n",
      "           1       0.90      0.94      0.92     19111\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     24013\n",
      "   macro avg       0.81      0.76      0.78     24013\n",
      "weighted avg       0.86      0.87      0.86     24013\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 2824  2078]\n",
      " [ 1127 17984]]\n",
      "Score: \n",
      "0.8665306292424937\n",
      "Cross validation score: \n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(gamma='scale') \n",
    "clf = clf.fit(X_train, y_train)\n",
    "expected = y_test\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (clf, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "print 'Score: '\n",
    "print clf.score(X_test,y_test)\n",
    "print 'Cross validation score: '\n",
    "print cross_val_score(clf, X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(50, 50), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.52      0.62      4902\n",
      "           1       0.89      0.96      0.92     19111\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     24013\n",
      "   macro avg       0.82      0.74      0.77     24013\n",
      "weighted avg       0.86      0.87      0.86     24013\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 2562  2340]\n",
      " [  815 18296]]\n",
      "Score: \n",
      "0.8686128347145297\n",
      "Cross validation score: \n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(50,50))\n",
    "clf = clf.fit(X_train, y_train)\n",
    "expected = y_test\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (clf, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "print 'Score: '\n",
    "print clf.score(X_test,y_test)\n",
    "print 'Cross validation score: '\n",
    "#print cross_val_score(clf, X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.45      0.58      4902\n",
      "           1       0.87      0.97      0.92     19111\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     24013\n",
      "   macro avg       0.85      0.71      0.75     24013\n",
      "weighted avg       0.86      0.87      0.85     24013\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 2198  2704]\n",
      " [  480 18631]]\n",
      "Score: \n",
      "0.8674051555407487\n",
      "Cross validation score: \n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "expected = y_test\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (clf, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "print 'Score: '\n",
    "print clf.score(X_test,y_test)\n",
    "print 'Cross validation score: '\n",
    "#print cross_val_score(clf, X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.55      0.64      4902\n",
      "           1       0.89      0.96      0.92     19111\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     24013\n",
      "   macro avg       0.83      0.75      0.78     24013\n",
      "weighted avg       0.87      0.87      0.87     24013\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 2701  2201]\n",
      " [  808 18303]]\n",
      "Score: \n",
      "0.8746928746928747\n",
      "Cross validation score: \n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "expected = y_test\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (clf, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "print 'Score: '\n",
    "print clf.score(X_test,y_test)\n",
    "print 'Cross validation score: '\n",
    "#print cross_val_score(clf, X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.50      0.62      4902\n",
      "           1       0.88      0.97      0.92     19111\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     24013\n",
      "   macro avg       0.84      0.74      0.77     24013\n",
      "weighted avg       0.87      0.87      0.86     24013\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 2465  2437]\n",
      " [  604 18507]]\n",
      "Score: \n",
      "0.8733602631907716\n",
      "Cross validation score: \n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "expected = y_test\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (clf, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "print 'Score: '\n",
    "print clf.score(X_test,y_test)\n",
    "print 'Cross validation score: '\n",
    "#print cross_val_score(clf, X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.57      0.65      4902\n",
      "           1       0.90      0.95      0.92     19111\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     24013\n",
      "   macro avg       0.83      0.76      0.79     24013\n",
      "weighted avg       0.87      0.88      0.87     24013\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 2811  2091]\n",
      " [  873 18238]]\n",
      "Score: \n",
      "0.8765668596177071\n",
      "Cross validation score: \n",
      "[0.87258287 0.87706333 0.87519856 0.87554389 0.87581158]\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "expected = y_test\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (clf, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "print 'Score: '\n",
    "print clf.score(X_test,y_test)\n",
    "print 'Cross validation score: '\n",
    "print cross_val_score(clf, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.55      0.64      4902\n",
      "           1       0.89      0.96      0.92     19111\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     24013\n",
      "   macro avg       0.83      0.75      0.78     24013\n",
      "weighted avg       0.87      0.88      0.87     24013\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 2686  2216]\n",
      " [  784 18327]]\n",
      "Score: \n",
      "0.8750676716778412\n",
      "Cross validation score: \n",
      "[0.87216851 0.87457697 0.8751295  0.87540576 0.8743611 ]\n"
     ]
    }
   ],
   "source": [
    "# Ada Boosting\n",
    "\n",
    "clf = AdaBoostClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "expected = y_test\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (clf, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "print 'Score: '\n",
    "print clf.score(X_test,y_test)\n",
    "print 'Cross validation score: '\n",
    "print cross_val_score(clf, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
